{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99eda13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "from datetime import date, datetime, timedelta\n",
    "from IPython.display import clear_output\n",
    "import scipy.stats as ss\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, PowerTransformer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dbf7786",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Tom\\\\Documents\\\\GitHub\\\\leek-growth-model\\\\zone_db.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-08284ff21463>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mgrowth_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrowth_data_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mweather_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweather_data_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mzone_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzone_data_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1043\u001b[0m             )\n\u001b[0;32m   1044\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1861\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1863\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1864\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m         \"\"\"\n\u001b[1;32m-> 1357\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1358\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Tom\\\\Documents\\\\GitHub\\\\leek-growth-model\\\\zone_db.csv'"
     ]
    }
   ],
   "source": [
    "# Get cwd as this changes depending on which laptop is being used.\n",
    "# Could probably use a relative reference but this may restrict development.\n",
    "# Import all required data from CSV files.\n",
    "\n",
    "directory = os.getcwd()\n",
    "\n",
    "growth_data_path = f\"{directory}\\\\growth_db.csv\"\n",
    "weather_data_path = f\"{directory}\\\\weather_db.csv\"\n",
    "zone_data_path = f\"{directory}\\\\zone_db.csv\"\n",
    "    \n",
    "growth_data = pd.read_csv(growth_data_path)\n",
    "weather_data = pd.read_csv(weather_data_path)\n",
    "zone_data = pd.read_csv(zone_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all data within a df is visible when printed.\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f7669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables used within script.\n",
    "\n",
    "linearisation_power = 0.625 # This is used to transform mean_diameter so it has a linear relationship with solar/heat.\n",
    "stripping_coef = 0.92 # This is to allow for a slight reduction in diameter once leeks are stripped at harvest.\n",
    "min_grow_temp = 3 # The minimum temperature that leeks will grow at. Needed to calculate heat units.\n",
    "max_grow_temp = 27 # The temperature at which maximum growth rate is achieved. Needed to calculate heat units.\n",
    "season = datetime(2022, 1, 1) # Output data only required for fields with a planting date in this season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98266d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature creation, alteration and exploration for weather data.\n",
    "\n",
    "weather_data['date'] = pd.to_datetime(weather_data['date'], format='%d/%m/%Y')\n",
    "weather_data['time'] = pd.to_datetime(weather_data['time'], format='%H:%M:%S')\n",
    "weather_data['day'] = weather_data.date.dt.day\n",
    "weather_data['month'] = weather_data.date.dt.month\n",
    "weather_data['day_month'] = weather_data['day'].astype(str) + \" - \" + weather_data['month'].astype(str) # This is used to calculate weather averages.\n",
    "\n",
    "# Calculate heat_units using min and max temperature variables.\n",
    "\n",
    "weather_data['heat_units'] = weather_data['avg_temp'] - min_grow_temp\n",
    "weather_data['heat_units'] = np.where((weather_data['heat_units'] < 0), 0, weather_data['heat_units'])\n",
    "weather_data['heat_units'] = np.where((weather_data['heat_units'] > max_grow_temp - min_grow_temp), 1, weather_data['heat_units']/24)\n",
    "\n",
    "weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc822d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate if any dates have something other than 24 datapoints as this must be an error.\n",
    "\n",
    "weather_data.date.value_counts()[weather_data.date.value_counts()!=24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d558e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960e275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature creation, alteration and exploration for growth data.\n",
    "\n",
    "growth_data['sample_date'] = pd.to_datetime(growth_data['sample_date'], format='%d/%m/%Y')\n",
    "growth_data['fieldzone'] = growth_data[\"field\"] + \" - \" + growth_data[\"zone\"].astype(str)\n",
    "growth_data['stripped_diameter'] = growth_data['diameter'] * stripping_coef\n",
    "\n",
    "growth_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c13fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_data.diameter.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844debf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature creation, alteration and exploration for zone data.\n",
    "\n",
    "zone_data['planting_date'] = pd.to_datetime(zone_data['planting_date'], format='%d/%m/%Y')\n",
    "zone_data['harvest_date'] = pd.to_datetime(zone_data['harvest_date'], format='%d/%m/%Y')\n",
    "zone_data['zone'] = zone_data['zone'].astype(int)\n",
    "zone_data[\"fieldzone\"] = zone_data[\"field\"] + \" - \" + zone_data[\"zone\"].astype(str)\n",
    "zone_data[\"fieldvariety\"] = zone_data[\"field\"] + \" - \" + zone_data[\"variety\"]\n",
    "\n",
    "zone_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ee0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc84fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f8128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start to build summary dataframe\n",
    "# This dataframe will be aggregated to fit models. Need to aggregate explained later.\n",
    "\n",
    "summary_data = growth_data.copy()\n",
    "\n",
    "summary_data[\"zone\"] = summary_data[\"zone\"].astype(str)\n",
    "summary_data[\"fieldzone\"] = summary_data[\"field\"] + \" - \" + summary_data[\"zone\"]\n",
    "summary_data['fieldzonedate'] = summary_data['fieldzone'] + \" - \" + summary_data['sample_date'].astype(str)\n",
    "\n",
    "summary_data = summary_data.set_index('fieldzone')\n",
    "summary_data = summary_data.join(zone_data.set_index('fieldzone'), rsuffix = '_join')\n",
    "\n",
    "summary_data['fieldvarietydate'] = summary_data['fieldvariety'] + \" - \" + summary_data['sample_date'].astype(str)\n",
    "summary_data['heat_units'] = 0\n",
    "summary_data['solar_radiation'] = 0\n",
    "\n",
    "summary_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96516948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and remove join columns from summary dataframe.\n",
    "\n",
    "summary_data = summary_data.reset_index(inplace=False)\n",
    "summary_data = summary_data.drop(columns=['field_join', 'zone_join'], inplace=False)\n",
    "summary_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b3102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness is how far the mode is to the right (positive) or left (negative) of the mean.\n",
    "# Kurtosis is the length of the tails on the distribution. Normal distribution has kurtosis of 3.\n",
    "\n",
    "def skewness(series):\n",
    "    \"\"\"Aggregate function to return skew of distribution\"\"\"\n",
    "    return ss.skew(series, bias = False)\n",
    "\n",
    "def kurt(series):\n",
    "    \"\"\"Aggregate function to return kurtosis of distribution\"\"\"\n",
    "    return ss.kurtosis(series, bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d17c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation of summary data to which can be used to fit models.\n",
    "# Non aggregated data can also be used to fit models but it will be more difficult to create a predicted distribution...\n",
    "# cont... due to not having a standard deviation variable which is generated during aggregation.\n",
    "\n",
    "summary_data_avg = summary_data.copy()\n",
    "\n",
    "summary_data_avg = summary_data_avg.groupby(['fieldzonedate']).agg({'stripped_diameter' : ['mean', 'std', 'count', skewness, kurt],\n",
    "                                                                    'method' : ['first'],\n",
    "                                                                    'inputs' : ['first'],\n",
    "                                                                    'variety' : ['first'],\n",
    "                                                                    'protection' : ['first'],\n",
    "                                                                    'sand' : ['mean'],\n",
    "                                                                    'silt' : ['mean'],\n",
    "                                                                    'clay' : ['mean'],\n",
    "                                                                    'organic_matter' : ['mean'],\n",
    "                                                                    'planting_rate' : ['first'],\n",
    "                                                                    'planting_date' : ['first'],\n",
    "                                                                    'sample_date' : ['first'],\n",
    "                                                                    'fieldzone' : ['first']}).reset_index()\n",
    "\n",
    "summary_data_avg.columns = ['fieldzonedate',\n",
    "                            'mean_diameter',\n",
    "                            'std_dev_diameter',\n",
    "                            'pp2m2',\n",
    "                            'skewness',\n",
    "                            'kurtosis',\n",
    "                            'method',\n",
    "                            'inputs',\n",
    "                            'variety',\n",
    "                            'protection',\n",
    "                            'sand',\n",
    "                            'silt',\n",
    "                            'clay',\n",
    "                            'organic_matter',\n",
    "                            'planting_rate',\n",
    "                            'planting_date',\n",
    "                            'sample_date',\n",
    "                            'fieldzone']\n",
    "\n",
    "summary_data_avg['field'] = summary_data_avg['fieldzone'].str.split(' - ').str[0]\n",
    "summary_data_avg['zone'] = summary_data_avg['fieldzone'].str.split(' - ').str[1]\n",
    "summary_data_avg['d_lin'] = (summary_data_avg['mean_diameter'])**linearisation_power\n",
    "summary_data_avg['s_lin'] = (summary_data_avg['std_dev_diameter'])**linearisation_power\n",
    "summary_data_avg['heat_units'] = 0\n",
    "summary_data_avg['solar_radiation'] = 0\n",
    "\n",
    "summary_data_avg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e568dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data_avg[['method', 'inputs', 'variety', 'protection', 'fieldzone', 'field']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd3ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data_avg[['planting_date', 'sample_date']].describe(datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc76b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data_avg[['mean_diameter', 'std_dev_diameter', 'pp2m2', 'skewness', 'kurtosis', 'sand', 'silt', 'clay', 'organic_matter', 'planting_rate']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9265a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation of weather data to create a more manageable dataframe as we only need day by day accuracy not hour by hour.\n",
    "\n",
    "weather_data_avg = weather_data.copy()\n",
    "\n",
    "weather_data_avg = weather_data_avg.groupby(['date']).agg({'rain' : ['sum'],\n",
    "                                                       'heat_units' : ['sum'],\n",
    "                                                       'solar_radiation' : ['sum'],\n",
    "                                                       'wind_speed_avg' : ['mean'],\n",
    "                                                       'rh' : ['mean'],\n",
    "                                                       'avg_temp' : ['mean']}).reset_index()\n",
    "\n",
    "weather_data_avg.columns = ['date',\n",
    "                            'rain',\n",
    "                            'heat_units',\n",
    "                            'solar_radiation',\n",
    "                            'wind_speed_avg',\n",
    "                            'rh',\n",
    "                            'avg_temp']\n",
    "\n",
    "weather_data_avg['day'] = weather_data_avg.date.dt.day\n",
    "weather_data_avg['month'] = weather_data_avg.date.dt.month\n",
    "weather_data_avg['day_month'] = weather_data_avg['day'].astype(str) + \" - \" + weather_data_avg['month'].astype(str)\n",
    "\n",
    "# Further aggregation of weather to get the average weather for a given day and a given month, regardless of the year.\n",
    "# This average weather will be used to predict heat and solar that a plant will receive.\n",
    "# Could possibly introduce some sort of short term weather forecast here???\n",
    "\n",
    "weather_data_avg_group = weather_data_avg.copy()\n",
    "\n",
    "weather_data_avg_group = weather_data_avg_group.groupby(['day_month']).agg({'rain' : ['mean'],\n",
    "                                                                            'heat_units' : ['mean'],\n",
    "                                                                            'solar_radiation' : ['mean'],\n",
    "                                                                            'wind_speed_avg' : ['mean'],\n",
    "                                                                            'rh' : ['mean'],\n",
    "                                                                            'avg_temp' : ['mean']}).reset_index()\n",
    "\n",
    "weather_data_avg_group.columns = ['day_month',\n",
    "                                  'rain',\n",
    "                                  'heat_units',\n",
    "                                  'solar_radiation',\n",
    "                                  'wind_speed_avg',\n",
    "                                  'rh',\n",
    "                                  'avg_temp']\n",
    "\n",
    "# Extend aggregated weather data by adding 300 days of predicted weather.\n",
    "\n",
    "max_date = max(weather_data_avg.date)\n",
    "\n",
    "for i in range(1, 300):\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    date = max_date + timedelta(days=i)\n",
    "    weather_data_avg = weather_data_avg.append({'date': date,\n",
    "                                                'rain': np.nan,\n",
    "                                                'heat_units':np.nan,\n",
    "                                                'solar_radiation':np.nan,\n",
    "                                                'wind_speed_avg':np.nan,\n",
    "                                                'rh':np.nan,\n",
    "                                                'avg_temp':np.nan }, ignore_index=True)\n",
    "    \n",
    "    print(\"Current Progress:\", np.round(i/300*100,0),\"%\")\n",
    "    \n",
    "weather_data_avg['day'] = weather_data_avg.date.dt.day\n",
    "weather_data_avg['month'] = weather_data_avg.date.dt.month\n",
    "weather_data_avg['day_month'] = weather_data_avg['day'].astype(str) + \" - \" + weather_data_avg['month'].astype(str)  \n",
    "\n",
    "weather_data_avg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3360ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_avg[weather_data_avg['solar_radiation']//1000000 != 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46de663",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "###THIS IS A VERY SLOW PROCESS (COULD PARALLEL PROCESSING BE INTRODUCED???)\n",
    "\n",
    "def mean_weather(day_month, variable):\n",
    "    \"\"\"function that calculates the average value for a weather variable for a given day within a given month\"\"\"\n",
    "    df = weather_data_avg_group[weather_data_avg_group['day_month']==day_month]\n",
    "    weather_value = df[variable].sum()\n",
    "    return weather_value\n",
    "\n",
    "for variable in ['rain', 'heat_units', 'solar_radiation', 'wind_speed_avg', 'rh', 'avg_temp']:\n",
    "    for i in weather_data_avg.index:\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # If statement so only future dates have weather predicted.\n",
    "        # Tried == np.nan, but that didn't work so workaround implemented. Make sure no variable has a value larger than 'MEGA_NUM'.\n",
    "        \n",
    "        MEGA_NUM = 10000000\n",
    "        \n",
    "        if weather_data_avg[variable][i]//MEGA_NUM != 0:\n",
    "            day_month = weather_data_avg['day_month'][i]\n",
    "            weather_data_avg[variable][i] = mean_weather(day_month, variable)\n",
    "            \n",
    "        print(f\"{variable} progress:\", np.round(i/len(weather_data_avg)*100,0),\"%\")\n",
    "    \n",
    "weather_data_avg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f1efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_avg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3743afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_weather(start, finish, weather_variable, weather_data):\n",
    "    \"\"\"Function used to find the cumulative weather input between 2 given dates\"\"\"\n",
    "    df = weather_data.loc[(weather_data['date'] > start) & (weather_data['date'] < finish), [weather_variable]]\n",
    "    total_units = df[weather_variable].sum()\n",
    "    return total_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add5bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite solar radiation with the cumulative total that has been received between planting and sampling.\n",
    "\n",
    "for i in summary_data_avg.index:\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    planting_date = summary_data_avg['planting_date'][i]\n",
    "    sample_date = summary_data_avg['sample_date'][i]\n",
    "    summary_data_avg['solar_radiation'][i] = cumulative_weather(planting_date, sample_date, 'solar_radiation', weather_data_avg)\n",
    "    \n",
    "    print(\"Current Progress:\", np.round(i/len(summary_data_avg)*100,0),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800cc36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite heat units with the cumulative total that has been received between planting and sampling.\n",
    "\n",
    "for i in summary_data_avg.index:\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    planting_date = summary_data_avg['planting_date'][i]\n",
    "    sample_date = summary_data_avg['sample_date'][i]\n",
    "    summary_data_avg['heat_units'][i] = cumulative_weather(planting_date, sample_date, 'heat_units', weather_data_avg)\n",
    "    \n",
    "    print(\"Current Progress:\", np.round(i/len(summary_data_avg)*100,0),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy code for protection column while retaining the original 'protection' series within the dataframe for visualisation purposes.\n",
    "# This allows a larger amount of data to be used within Lin Reg model as df does not need to be filtered based on protection.\n",
    "\n",
    "summary_data_avg['protection_2'] = summary_data_avg['protection'].copy()\n",
    "summary_data_avg = pd.get_dummies(summary_data_avg, columns = ['protection'], drop_first = False)\n",
    "summary_data_avg.rename(columns={'protection_2': 'protection'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03788efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data_avg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f3ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots to check for outliers in continuous variables of importance.\n",
    "\n",
    "sns.boxplot(x = 'inputs', y = 'pp2m2', data = summary_data_avg, hue = 'method', orient = 'v')\n",
    "plt.legend(bbox_to_anchor=(0.45, 0.97), loc='upper left', borderaxespad=0)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x = 'method', y = 'heat_units', data = summary_data_avg, orient = 'v')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x = 'method', y = 'solar_radiation', data = summary_data_avg, orient = 'v')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x = 'method', y = 'mean_diameter', data = summary_data_avg, orient = 'v')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x = 'method', y = 'std_dev_diameter', data = summary_data_avg, orient = 'v')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data = summary_data_avg[['sand', 'silt', 'clay', 'organic_matter']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625196a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts of categorical variables of importance.\n",
    "\n",
    "summary_data_avg['variety'].value_counts().plot(kind = 'bar', xlabel = 'variety', ylabel = 'count')\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.show()\n",
    "\n",
    "summary_data_avg['method'].value_counts().plot(kind = 'bar', xlabel = 'method', ylabel = 'count')\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.show()\n",
    "\n",
    "summary_data_avg['inputs'].value_counts().plot(kind = 'bar', xlabel = 'inputs', ylabel = 'count')\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.show()\n",
    "\n",
    "summary_data_avg['protection'].value_counts().plot(kind = 'bar', xlabel = 'protection', ylabel = 'count')\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad16aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any null values and if any are present, find out why.\n",
    "\n",
    "summary_data_avg[summary_data_avg.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497586f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove any null values to prevent failure but if any are present, it's essential to find out why.\n",
    "\n",
    "summary_data_avg = summary_data_avg.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11813cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_count(fieldzone, df_1 = summary_data_avg):\n",
    "    \"\"\"Function used to find the average plants per two meters squared from every sample from a given fieldzone over the entire season\"\"\"\n",
    "    \n",
    "    df_1 = df_1[df_1['fieldzone']==fieldzone]\n",
    "    average_count = df_1['pp2m2'].mean()\n",
    "    \n",
    "    if mt.isnan(average_count):\n",
    "        average_count = 40\n",
    "      \n",
    "    return average_count\n",
    "\n",
    "int(average_count('RH33 - 1')) == 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530efead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_sample_date(fieldzone, df_1 = summary_data_avg, df_2 = zone_data):\n",
    "    \"\"\"Function used to find the most recent sample date for a given fieldzone\"\"\"\n",
    "    \n",
    "    df_1 = df_1[df_1['fieldzone'] == fieldzone]\n",
    "    max_sample_date = max(df_1['sample_date'], default = 0)\n",
    "    if max_sample_date == 0:\n",
    "        df_2 = df_2[df_2['fieldzone'] == fieldzone]\n",
    "        max_sample_date = df_2['planting_date'].max()\n",
    "    \n",
    "    return max_sample_date\n",
    "\n",
    "max_sample_date('RH33 - 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c632182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_mean_diameter_lin(fieldzone, df_1 = summary_data_avg):\n",
    "    \"\"\"Function used to find the mean diameter of the sample at the most recent sample date\"\"\"\n",
    "    \n",
    "    df_1 = df_1[df_1['fieldzone']==fieldzone]\n",
    "    max_mean_diameter = df_1['mean_diameter'].max()\n",
    "    max_mean_diameter_lin = max_mean_diameter ** linearisation_power\n",
    "    \n",
    "    if mt.isnan(max_mean_diameter_lin):\n",
    "        max_mean_diameter_lin = 0\n",
    "    \n",
    "    return max_mean_diameter_lin\n",
    "\n",
    "int(max_mean_diameter_lin('Allans 07 - 1')) == 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd1ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_std_dev_diameter_lin(fieldzone, df_1 = summary_data_avg):\n",
    "    \"\"\"Function used to find the standard deviation of the sample at the most recent sample date\"\"\"\n",
    "    \n",
    "    df_1 = df_1[df_1['fieldzone']==fieldzone]\n",
    "    max_std_dev_diameter = df_1['std_dev_diameter'].max()\n",
    "    max_std_dev_diameter_lin = max_std_dev_diameter ** linearisation_power\n",
    "    \n",
    "    if mt.isnan(max_std_dev_diameter_lin):\n",
    "        max_std_dev_diameter_lin = 0\n",
    "    \n",
    "    return max_std_dev_diameter_lin\n",
    "\n",
    "int(max_std_dev_diameter_lin('Allans 07 - 1')) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f424cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_solar(fieldzone, df_1 = summary_data_avg):\n",
    "    \"\"\"Function used to find the solar radiation received at the most recent sample date\"\"\"\n",
    "    \n",
    "    df_1 = df_1[df_1['fieldzone']==fieldzone]\n",
    "    max_solar = df_1['solar_radiation'].max()\n",
    "    \n",
    "    if mt.isnan(max_solar):\n",
    "        max_solar = 0\n",
    "    \n",
    "    return max_solar\n",
    "\n",
    "max_solar('Allans 07 - 1') == 1600496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f75d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_heat(fieldzone, df_1 = summary_data_avg):\n",
    "    \"\"\"Function used to find the heat units received at the most recent sample date\"\"\"\n",
    "    \n",
    "    df_1 = df_1[df_1['fieldzone']==fieldzone]\n",
    "    max_heat = df_1['heat_units'].max()\n",
    "    \n",
    "    if mt.isnan(max_heat):\n",
    "        max_heat = 0\n",
    "    \n",
    "    return max_heat\n",
    "\n",
    "max_heat('Allans 07 - 1') == 2464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc7b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(data, method, inputs, variety):\n",
    "    \"\"\"Function used to filter df so it only contains a single variety, input & method\"\"\"\n",
    "    \n",
    "    filtered = data[data['variety'].str.contains(variety)]\n",
    "    filtered = filtered[filtered['inputs'].str.contains(inputs)]\n",
    "    filtered = filtered[filtered['method'].str.contains(method)]\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b279c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_weather(start, finish, variable, df_1 = weather_data):\n",
    "    \"\"\"Function used to calculated a predicted weather variable for a given timeframe\"\"\"\n",
    "    \n",
    "    df_1 = df_1.loc[(df_1['date'] > start) & (df_1['date'] < finish), [variable]]\n",
    "    predicted_weather= df_1[variable].sum()\n",
    "    \n",
    "    return predicted_weather\n",
    "\n",
    "start = datetime(year=2021, month=6, day=2, hour=13, minute=14, second=31)\n",
    "finish = datetime(year=2022, month=6, day=2, hour=13, minute=14, second=31)\n",
    "\n",
    "predict_weather(start, finish, 'rain') == 434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb79fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This df will be used for Linear Regression model and Visualisation. Prediction will be taken from the most recent (maximum) sample date...\n",
    "# The 'max' variables just indicate the result of the most recent sample at that zone.\n",
    "\n",
    "zone_data['mean_pp2m2'] = 0.0\n",
    "zone_data['max_sample_date'] = 0\n",
    "zone_data['max_mean_diameter_lin'] = 0.0\n",
    "zone_data['max_std_dev_diameter_lin'] = 0.0\n",
    "zone_data['max_heat'] = 0.0\n",
    "zone_data['max_solar'] = 0.0\n",
    "zone_data['remaining_heat'] = 0.0\n",
    "zone_data['remaining_solar'] = 0.0\n",
    "zone_data['rain_after_planting'] = 0\n",
    "\n",
    "for i in zone_data.index:\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    fieldzone = zone_data.loc[i, 'fieldzone']\n",
    "    zone_data.loc[i, 'mean_pp2m2'] = average_count(fieldzone)\n",
    "    zone_data.loc[i, 'max_sample_date'] = max_sample_date(fieldzone)\n",
    "    zone_data.loc[i, 'max_mean_diameter_lin'] = max_mean_diameter_lin(fieldzone)\n",
    "    zone_data.loc[i, 'max_std_dev_diameter_lin'] = max_std_dev_diameter_lin(fieldzone)\n",
    "    zone_data.loc[i, 'max_heat'] = max_heat(fieldzone)\n",
    "    zone_data.loc[i, 'max_solar'] = max_solar(fieldzone)\n",
    "    start = zone_data.loc[i, 'max_sample_date']\n",
    "    finish = zone_data.loc[i, 'harvest_date']\n",
    "    rain_start = zone_data.loc[i, 'planting_date']\n",
    "    rain_finish = rain_start + timedelta(days = 14)\n",
    "    zone_data.loc[i, 'remaining_heat'] = cumulative_weather(start, finish, 'heat_units', weather_data_avg)\n",
    "    zone_data.loc[i, 'remaining_solar'] = cumulative_weather(start, finish, 'solar_radiation', weather_data_avg)\n",
    "    zone_data.loc[i, 'rain_after_planting'] = cumulative_weather(rain_start, rain_finish, 'rain', weather_data_avg)  \n",
    "    \n",
    "    print(\"Current Progress:\", np.round(i/len(zone_data)*100,0),\"%\")\n",
    "    \n",
    "zone_data['establishment'] = (zone_data['mean_pp2m2']/2*10000)/zone_data['planting_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5236fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These columns will be populated within the Lin Reg script.\n",
    "\n",
    "zone_data['est_mean_diameter_gain'] = 0.0\n",
    "zone_data['est_std_dev_diameter_gain'] = 0.0\n",
    "zone_data['est_mean_diameter'] = 0.0\n",
    "zone_data['est_std_dev_diameter'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Transformer\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor \n",
    "    def __init__(self, method):\n",
    "        self.cat_column_list = list(X.select_dtypes(include=[\"object_\"]))\n",
    "        self.method = method\n",
    "       \n",
    "    def fit(self, X, y = None):\n",
    "\n",
    "        if self.method.lower() = 'ordinal':\n",
    "            self.trns = OrdinalEncoder().fit(X[self.column_list])\n",
    "            \n",
    "        if self.method.lower() = 'onehot':\n",
    "            self.trns = OneHotEncoder().fit(X[self.column_list])\n",
    "\n",
    "        return self\n",
    "        \n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        \n",
    "        pd.options.mode.chained_assignment = None  # default='warn'\n",
    "        trns_array = self.trns.transform(X[self.column_list])\n",
    "        X.loc[:, self.column_list] = trns_array.copy()\n",
    "\n",
    "        return X\n",
    "        \n",
    "        \n",
    "    def inverse_transform(self, X, y = None):\n",
    "        \n",
    "        pd.options.mode.chained_assignment = None  # default='warn'\n",
    "        trns_array = self.trns.inverse_transform(X[self.column_list])\n",
    "        X.loc[:, self.column_list] = trns_array.copy()\n",
    "            \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2cb89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b87dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345bb03e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5b322d1f5beaecfb28b050f61b5bc2c682da0c88a01138942a1439f934c1c07"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
