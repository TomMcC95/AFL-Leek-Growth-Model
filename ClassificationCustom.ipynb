{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b15e0fc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Progress: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "%run PreProcessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d369ac1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-61a766c40790>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  summary_data_avg['harvest_timing'] = 'optimal'\n",
      "c:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "summary_data_avg = summary_data_avg[summary_data_avg.inputs != 'Conventional']\n",
    "summary_data_avg['harvest_timing'] = 'optimal'\n",
    "summary_data_avg.loc[summary_data_avg['mean_diameter'] < 25, 'harvest_timing'] = 'early'\n",
    "summary_data_avg.loc[summary_data_avg['mean_diameter'] < 30, 'harvest_timing'] = 'suitable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd496bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = summary_data_avg[['heat_units', 'solar_radiation', 'organic_matter', 'sand', 'silt', 'clay', 'method', 'variety', 'inputs', 'protection']]\n",
    "y = summary_data_avg['harvest_timing']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 10, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e0499ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suitable    378\n",
      "Name: harvest_timing, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f323117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The old training dataframe shape: (378, 10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Drilled'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c7be957e9ce0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#Use the algorithm for outlier detection, then use it to predict each point\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mclf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIsolationForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontamination\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#Any point labelled as -1 is an outlier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m    749\u001b[0m         \u001b[1;31m# override for transductive outlier detectors like LocalOulierFactor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\ensemble\\_iforest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \"\"\"\n\u001b[1;32m--> 241\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[1;31m# Pre-sort indices to avoid that each individual tree of the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mc:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1898\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1900\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32mc:\\users\\tom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Drilled'"
     ]
    }
   ],
   "source": [
    "#Isolation forest algorithm to show unsupervised learning\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "print(f\"The old training dataframe shape: {X_train.shape}\")\n",
    "\n",
    "#Use the algorithm for outlier detection, then use it to predict each point\n",
    "clf1 = IsolationForest(max_samples=500, random_state = 10, contamination= 'auto')\n",
    "preds = clf1.fit_predict(X_train)\n",
    "\n",
    "#Any point labelled as -1 is an outlier\n",
    "totalOutliers=0\n",
    "for pred in preds:\n",
    "    if pred == -1:\n",
    "        totalOutliers=totalOutliers+1\n",
    "print(\"Total number of outliers identified is: \",totalOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49642313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers from training data.\n",
    "filtered_array = []\n",
    "for element in preds:\n",
    "  if element != -1:\n",
    "    filtered_array.append(True)\n",
    "  else:\n",
    "    filtered_array.append(False)\n",
    "X_train = X_train[filtered_array]\n",
    "y_train = y_train[filtered_array]\n",
    "\n",
    "print(f\"The new training dataframe shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c15131",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bcfd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "chosen_feat_list = list(X_train)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "\n",
    "train_df = pd.merge(X_train, y_train, right_index=True, left_index=True)\n",
    "\n",
    "early_df = train_df[train_df['harvest_timing']=='early']\n",
    "suitable_df = train_df[train_df['harvest_timing']=='suitable']\n",
    "optimal_df = train_df[train_df['harvest_timing']=='optimal']\n",
    "\n",
    "n = 500\n",
    "\n",
    "early_resampled = resample(early_df, replace=True, n_samples=n, random_state=10)\n",
    "suitable_resampled = resample(suitable_df, replace=True, n_samples=n, random_state=10)\n",
    "optimal_resampled = resample(optimal_df, replace=True, n_samples=n, random_state=10)\n",
    "\n",
    "train_df_resampled = pd.concat([early_resampled, suitable_resampled, optimal_resampled], ignore_index=True)\n",
    "\n",
    "X_train = train_df_resampled[chosen_feat_list]\n",
    "y_train = train_df_resampled['harvest_timing']\n",
    "\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c2dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create supervised classification models\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils import *\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a1ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty': ['l1', 'l2', 'elasticnet'],  \n",
    "              'alpha': [0.0001, 0.001], \n",
    "              'random_state': [10],\n",
    "              'loss': ['hinge', 'modified_huber', 'perceptron']}  \n",
    "   \n",
    "grid_sgd = GridSearchCV(SGDClassifier(), param_grid, refit = True, verbose = 3,n_jobs=-1) \n",
    "   \n",
    "# fitting the model for grid search \n",
    "grid_sgd.fit(X_train_scaled, y_train.values.ravel()) \n",
    " \n",
    "# print best parameter after tuning \n",
    "print(grid_sgd.best_params_) \n",
    "grid_sgd_preds = grid_sgd.predict(X_test_scaled) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_sgd_preds, zero_division = 0)) \n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, grid_sgd_preds)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predicted', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('SGD Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "sgd = SGDClassifier(random_state = 10, alpha = 0.001, loss = 'hinge', penalty = 'l1')\n",
    "sgd_model = sgd.fit(X_train_scaled, y_train.values.ravel())\n",
    "sgd_model_pred = sgd_model.predict(X_test_scaled)\n",
    "sgd_accuracy = accuracy_score(y_test, sgd_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'var_smoothing': [0.000000001, 0.00000001, 0.00000000001]}  \n",
    "   \n",
    "grid_gnb = GridSearchCV(GaussianNB(), param_grid, refit = True, verbose = 3,n_jobs=-1) \n",
    "   \n",
    "# fitting the model for grid search \n",
    "grid_gnb.fit(X_train_scaled, y_train.values.ravel()) \n",
    " \n",
    "# print best parameter after tuning \n",
    "print(grid_gnb.best_params_) \n",
    "grid_gnb_preds = grid_gnb.predict(X_test_scaled) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_gnb_preds, zero_division = 0)) \n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, grid_gnb_preds)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predicted', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('GaussianNB Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "gnb = GaussianNB(var_smoothing = 0.000000001)\n",
    "gnb_model = gnb.fit(X_train_scaled, y_train.values.ravel())\n",
    "gnb_model_pred = gnb_model.predict(X_test_scaled)\n",
    "gnb_accuracy = accuracy_score(y_test, gnb_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd50a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'gamma': ['scale', 'auto'],\n",
    "              'kernel': ['linear', 'poly', 'rbf']}  \n",
    "   \n",
    "grid_svc = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3,n_jobs=-1) \n",
    "   \n",
    "# fitting the model for grid search \n",
    "grid_svc.fit(X_train_scaled, y_train.values.ravel()) \n",
    " \n",
    "# print best parameter after tuning \n",
    "print(grid_svc.best_params_) \n",
    "grid_svc_preds = grid_svc.predict(X_test_scaled) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_svc_preds, zero_division = 0)) \n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, grid_svc_preds)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predicted', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('SVM Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "svc = SVC(random_state = 10, gamma = 'scale', kernel = 'linear')\n",
    "svc_model = svc.fit(X_train_scaled, y_train.values.ravel())\n",
    "svc_model_pred = svc_model.predict(X_test_scaled)\n",
    "svc_accuracy = accuracy_score(y_test, svc_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f6f65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'random_state': [10],\n",
    "              'solver': ['newton-cg', 'lbfgs'],\n",
    "              'C': [1, 0.5],\n",
    "              'max_iter': [250, 400]}  \n",
    "   \n",
    "grid_lr = GridSearchCV(LogisticRegression(), param_grid, refit = True, verbose = 3,n_jobs=-1) \n",
    "   \n",
    "# fitting the model for grid search \n",
    "grid_lr.fit(X_train_scaled, y_train.values.ravel()) \n",
    " \n",
    "# print best parameter after tuning \n",
    "print(grid_lr.best_params_) \n",
    "grid_lr_preds = grid_lr.predict(X_test_scaled) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_lr_preds, zero_division = 0)) \n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, grid_lr_preds)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predicted', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Logistic Regression Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "lr = LogisticRegression(random_state = 10, max_iter = 250, C = 1, solver = 'newton-cg')\n",
    "lr_model = lr.fit(X_train_scaled, y_train.values.ravel())\n",
    "lr_model_pred = lr_model.predict(X_test_scaled)\n",
    "lr_accuracy = accuracy_score(y_test, lr_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e1c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'criterion': ['gini', 'entropy'],  \n",
    "              'splitter': ['best', 'random'], \n",
    "              'random_state': [11],\n",
    "              'max_features': [None, 'auto']}  \n",
    "   \n",
    "grid_dtc = GridSearchCV(DecisionTreeClassifier(), param_grid, refit = True, verbose = 3,n_jobs=-1) \n",
    "   \n",
    "# fitting the model for grid search \n",
    "grid_dtc.fit(X_train_scaled, y_train.values.ravel()) \n",
    " \n",
    "# print best parameter after tuning \n",
    "print(grid_dtc.best_params_) \n",
    "grid_dtc_preds = grid_dtc.predict(X_test_scaled) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_dtc_preds, zero_division = 0)) \n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, grid_dtc_preds)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predicted', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Decision Tree Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "dtc = DecisionTreeClassifier(criterion = 'gini', random_state = 11, max_features = None, splitter = 'best')\n",
    "dtc_model = dtc.fit(X_train_scaled, y_train.values.ravel())\n",
    "dtc_model_pred = dtc_model.predict(X_test_scaled)\n",
    "dtc_accuracy = accuracy_score(y_test, dtc_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4395390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pack the classifiers and string into a list of tuples.\n",
    "ensemble_clf = VotingClassifier([(\"LR\", lr), (\"SGD\", sgd), (\"DTC\", dtc), (\"SVC\", svc)], voting=\"hard\")\n",
    "ensemble_clf.fit(X_train_scaled, y_train.values.ravel())\n",
    "ensemble_clf_preds = ensemble_clf.predict(X_test_scaled)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_clf_preds)\n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, ensemble_clf_preds, zero_division = 0)) \n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, ensemble_clf_preds)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predicted', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Ensemble Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#....passing it into a bagging classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging = BaggingClassifier(ensemble_clf, n_estimators=10, random_state = 10)\n",
    "bagging.fit(X_train_scaled, y_train.values.ravel())\n",
    "bagging_preds = bagging.predict(X_test_scaled)\n",
    "bagging_accuracy = accuracy_score(y_test, bagging_preds)\n",
    "   \n",
    "print(classification_report(y_test, bagging_preds, zero_division = 0)) \n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, bagging_preds)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predicted', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Bagged Ensemble Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e556fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'criterion': ['gini', 'entropy'],  \n",
    "              'class_weight': [None, 'balanced_subsample'], \n",
    "              'random_state': [10],\n",
    "              'max_features': ['auto', 'sqrt', 'log2']}  \n",
    "   \n",
    "grid_rfc = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 3,n_jobs=-1) \n",
    "   \n",
    "# fitting the model for grid search \n",
    "grid_rfc.fit(X_train_scaled, y_train.values.ravel()) \n",
    " \n",
    "# print best parameter after tuning \n",
    "print(grid_rfc.best_params_) \n",
    "grid_rfc_preds = grid_rfc.predict(X_test_scaled) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_rfc_preds, zero_division = 0)) \n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, grid_rfc_preds)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predicted', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Random Forest Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "rfc = RandomForestClassifier(criterion = 'gini', class_weight = 'balanced_subsample', random_state = 10, max_features = 'auto')\n",
    "rfc_model = rfc.fit(X_train_scaled, y_train.values.ravel())\n",
    "rfc_model_pred = rfc_model.predict(X_test_scaled)\n",
    "rfc_accuracy = accuracy_score(y_test, rfc_model_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1e4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
